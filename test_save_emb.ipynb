{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "from l3embedding.model import *\n",
    "from l3embedding.audio import pcm2float\n",
    "import umap\n",
    "from sklearn.manifold import TSNE\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sk7898/miniconda3/envs/l3embedding-new-cpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1238: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/sk7898/miniconda3/envs/l3embedding-new-cpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1255: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/sk7898/miniconda3/envs/l3embedding-new-cpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1204: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sk7898/miniconda3/envs/l3embedding-new-cpu/lib/python3.6/site-packages/librosa/filters.py:261: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  warnings.warn('Empty filters detected in mel frequency basis. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fmax: None\n",
      "<bound method Container.summary of <keras.engine.training.Model object at 0x2b9fb31345c0>>\n"
     ]
    }
   ],
   "source": [
    "graph = tf.get_default_graph()\n",
    "weight_path = 'models/cnn_l3_melspec2_recent/model_best_valid_accuracy.h5'\n",
    "audio_model = load_embedding(weight_path, model_type = 'cnn_L3_melspec2', embedding_type = 'audio', \\\n",
    "                             pooling_type = 'short', kd_model=False, tgt_num_gpus = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(data, method, emb_len=None, neighbors=10, metric='euclidean', \\\n",
    "                min_dist=0.3, iterations=500):\n",
    "    \n",
    "    if len(data) == 0:\n",
    "        raise ValueError('Data is empty!')\n",
    "    if emb_len is None:\n",
    "        raise ValueError('Reduced embedding dimension was not provided!')\n",
    "\n",
    "    if method == 'umap':\n",
    "        embedding = umap.umap_.UMAP(n_neighbors=neighbors, min_dist=min_dist, metric=metric, \\\n",
    "                                    n_components=emb_len).fit_transform(data)\n",
    "    elif method == 'tsne':\n",
    "        embedding = TSNE(perplexity=neighbors, n_components=emb_len, metric=metric, \\\n",
    "                         n_iter=iterations, method='exact').fit_transform(data)\n",
    "    else:\n",
    "        raise ValueError('Reduction method technique should be either `umap` or `tsne`!')\n",
    "    \n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blob_keys(method, batch_size, emb_len, neighbor_list=None, metric_list=None, min_dist_list=None, tsne_iter_list=None):\n",
    "    \n",
    "    embedding_keys = []\n",
    "    \n",
    "    if method == 'umap':\n",
    "        if neighbor_list is None or metric_list is None or min_dist_list is None:\n",
    "            raise ValueError('Either neighbor_list or metric_list or min_dist_list is missing')\n",
    "        \n",
    "        [embedding_keys.append('umap/emb_' + str(emb_len) +\\\n",
    "                               '_batch_' + str(batch_size) + \\\n",
    "                               '_k_' + str(neighbors) + \\\n",
    "                               '_metric_' + metric + \\\n",
    "                               '_dist|iter_' + str(min_dist)) \\\n",
    "                                for neighbors in neighbor_list for metric in metric_list for min_dist in min_dist_list]\n",
    "                    \n",
    "    elif method == 'tsne':\n",
    "        if neighbor_list is None or metric_list is None or tsne_iter_list is None:\n",
    "            raise ValueError('Either neighbor_list or metric_list or tsne_iter_list is missing')\n",
    "        \n",
    "        [embedding_keys.append('tsne/emb_' + str(emb_len) +\\\n",
    "                               '_batch_' + str(batch_size) + \\\n",
    "                               '_k_' + str(neighbors) + \\\n",
    "                               '_metric_' + metric + \\\n",
    "                               '_dist|iter_' + str(iteration)) \\\n",
    "                                for neighbors in neighbor_list for metric in metric_list for iteration in tsne_iter_list]\n",
    "\n",
    "    return embedding_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(data_dir, reduced_emb_len, output_dir, reduction_method='umap', neighbor_list=None, \\\n",
    "                   metric_list=None, min_dist_list=None, tsne_iter_list=[500], \\\n",
    "                   batch_size=1024, random_state=20180123, start_batch_idx=None):\n",
    "\n",
    "    if data_dir == output_dir:\n",
    "        raise ValueError('Output path should not be same as data path to avoid overwriting data files!')\n",
    "        \n",
    "    if neighbor_list is None:\n",
    "        raise ValueError('Neighbor cannot be None!')\n",
    "    \n",
    "    if metric_list is None:\n",
    "        metric_list = ['euclidean']\n",
    "        print('Training UMAP with default value of metric: euclidean')\n",
    "    if reduction_method == 'umap' and min_dist_list is None:\n",
    "        min_dist_list = [0.3]\n",
    "        print('Training UMAP with default value of min_dist: 0.3')\n",
    "        \n",
    "    random.seed(random_state)\n",
    "    \n",
    "    batch = None\n",
    "    global graph\n",
    "    global audio_model\n",
    "    curr_batch_size = 0\n",
    "    batch_idx = 0\n",
    "    keys = ['audio']\n",
    "    blob_keys = get_blob_keys(reduction_method, batch_size, reduced_emb_len, neighbor_list=neighbor_list, \\\n",
    "                              metric_list=metric_list, min_dist_list=min_dist_list, tsne_iter_list=tsne_iter_list)\n",
    "    print(blob_keys)\n",
    "    \n",
    "    for fname in os.listdir(data_dir):\n",
    "        print('Filename: ', fname)\n",
    "        \n",
    "        blob_embeddings = dict()\n",
    "        batch_path = os.path.join(data_dir, fname)\n",
    "        blob_start_idx = 0\n",
    "        blob_end_idx = 0\n",
    "\n",
    "        blob = h5py.File(batch_path, 'r')\n",
    "        blob_size = len(blob['label'])\n",
    "\n",
    "        old_embeddings = np.zeros((blob_size, 512), dtype=np.float32)\n",
    "        embedding_out_path = os.path.join(output_dir, fname)\n",
    "\n",
    "        while blob_start_idx < blob_size:\n",
    "            blob_end_idx = min(blob_start_idx + batch_size - curr_batch_size, blob_size)\n",
    "\n",
    "            # If we are starting from a particular batch, skip computing all of\n",
    "            # the prior batches\n",
    "            if start_batch_idx is None or batch_idx >= start_batch_idx:\n",
    "                if batch is None:\n",
    "                    batch = {k:blob[k][blob_start_idx:blob_end_idx]\n",
    "                             for k in keys}\n",
    "                else:\n",
    "                    for k in keys:\n",
    "                        batch[k] = np.concatenate([batch[k],\n",
    "                                                   blob[k][blob_start_idx:blob_end_idx]])\n",
    "\n",
    "            curr_batch_size += blob_end_idx - blob_start_idx\n",
    "\n",
    "            if blob_end_idx == blob_size:\n",
    "                blob.close()\n",
    "\n",
    "            if curr_batch_size == batch_size:\n",
    "                # If we are starting from a particular batch, skip yielding all\n",
    "                # of the prior batches\n",
    "                if start_batch_idx is None or batch_idx >= start_batch_idx:\n",
    "                    # Convert audio to float\n",
    "                    batch['audio'] = pcm2float(batch['audio'], dtype='float32')\n",
    "                    # Get the embedding layer output from the audio_model and flatten it to be treated as labels for the student audio model\n",
    "                    with graph.as_default():\n",
    "                        teacher_embedding = audio_model.predict(batch['audio'])\n",
    "\n",
    "                    old_embeddings[blob_start_idx:blob_end_idx, :] = teacher_embedding\n",
    "                    \n",
    "                    if reduction_method == 'umap':\n",
    "                        n_process = len(neighbor_list) * len(metric_list) * len(min_dist_list)\n",
    "                        \n",
    "                        results = Parallel(n_jobs=-1)(delayed(get_embedding)(teacher_embedding, 'umap', \\\n",
    "                                                                             emb_len=reduced_emb_len, \\\n",
    "                                                                             neighbors=neighbors, \\\n",
    "                                                                             metric=metric, \\\n",
    "                                                                             min_dist=min_dist) \\\n",
    "                                          for neighbors in neighbor_list for metric in metric_list for min_dist in min_dist_list)\n",
    "\n",
    "                    elif reduction_method == 'tsne':\n",
    "                        n_process = len(neighbor_list) * len(metric_list) * len(tsne_iter_list)\n",
    "                        \n",
    "                        results = Parallel(n_jobs=-1)(delayed(get_embedding)(teacher_embedding, 'tsne', \\\n",
    "                                                                             emb_len=reduced_emb_len, \\\n",
    "                                                                             neighbors=neighbors, \\\n",
    "                                                                             metric=metric, \\\n",
    "                                                                             iterations=iterations) \\\n",
    "                                          for neighbors in neighbor_list for metric in metric_list for iterations in tsne_iter_list)\n",
    "\n",
    "                        assert len(results) == n_process\n",
    "                        \n",
    "                        for idx in range(len(results)):\n",
    "                            if blob_keys[idx] not in blob_embeddings.keys():    \n",
    "                                blob_embeddings[blob_keys[idx]] = np.zeros((blob_size, reduced_emb_len), dtype=np.float32)\n",
    "                                blob_embeddings[blob_keys[idx]][blob_start_idx:blob_end_idx,:] = results[idx]\n",
    "                            else:\n",
    "                                blob_embeddings[blob_keys[idx]][blob_start_idx:blob_end_idx,:] = results[idx]\n",
    "                                        \n",
    "                blob_start_idx = blob_end_idx\n",
    "                batch_idx += 1\n",
    "                curr_batch_size = 0\n",
    "                batch = None\n",
    "                print('One batch done')\n",
    "\n",
    "        if os.path.exists(embedding_out_path):\n",
    "            mode = 'a' \n",
    "        else:\n",
    "            mode = 'w'\n",
    "            \n",
    "        with h5py.File(embedding_out_path, mode) as f:\n",
    "            if 'embedding' not in f.keys():\n",
    "                f.create_dataset('embedding', data=old_embeddings) \n",
    "            for key in blob_keys:\n",
    "                if key in f.keys():\n",
    "                    continue\n",
    "                f.create_dataset(key, data=blob_embeddings[key])\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UMAP Hyperparams (16 jobs)\n",
    "#batches = [1024, 2048]\n",
    "#n_neighbors_umap = [20, 30, 40]\n",
    "#min_dist = [0.3, 0.5]\n",
    "#metric = ['correlation', 'euclidean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['umap/emb_256_batch_1024_k_20_metric_euclidean_dist|iter_0.3', 'umap/emb_256_batch_1024_k_20_metric_euclidean_dist|iter_0.5', 'umap/emb_256_batch_1024_k_20_metric_correlation_dist|iter_0.3', 'umap/emb_256_batch_1024_k_20_metric_correlation_dist|iter_0.5', 'umap/emb_256_batch_1024_k_30_metric_euclidean_dist|iter_0.3', 'umap/emb_256_batch_1024_k_30_metric_euclidean_dist|iter_0.5', 'umap/emb_256_batch_1024_k_30_metric_correlation_dist|iter_0.3', 'umap/emb_256_batch_1024_k_30_metric_correlation_dist|iter_0.5']\n",
      "Filename:  20180261_7_35.h5\n",
      "One batch done\n",
      "Filename:  20180261_7_34.h5\n",
      "One batch done\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/scratch/sk7898/temp_data'\n",
    "output_dir = '/scratch/sk7898/reduced_embeddings'\n",
    "reduced_emb_len = 256\n",
    "neighbor_list = [20, 30]\n",
    "min_dist_list = [0.3, 0.5]\n",
    "metric_list = ['euclidean', 'correlation']\n",
    "\n",
    "data_generator(data_dir, reduced_emb_len, output_dir, reduction_method='umap', \\\n",
    "               neighbor_list=neighbor_list, metric_list=metric_list, min_dist_list=min_dist_list, \\\n",
    "               batch_size=1024, random_state=20180123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tsne/emb_256_batch_1024_k_20_metric_euclidean_dist|iter_500', 'tsne/emb_256_batch_1024_k_20_metric_correlation_dist|iter_500', 'tsne/emb_256_batch_1024_k_30_metric_euclidean_dist|iter_500', 'tsne/emb_256_batch_1024_k_30_metric_correlation_dist|iter_500']\n",
      "Filename:  20180261_7_35.h5\n"
     ]
    }
   ],
   "source": [
    "tsne_iter_list = [500]\n",
    "data_generator(data_dir, reduced_emb_len, output_dir, reduction_method='tsne', \\\n",
    "               neighbor_list=neighbor_list, metric_list=metric_list, tsne_iter_list=tsne_iter_list, \\\n",
    "               batch_size=1024, random_state=20180123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 512)\n",
      "Key umap has output shape <HDF5 dataset \"emb_256_batch_1024_k_20_metric_correlation_dist|iter_0.3\": shape (1024, 256), type \"<f4\">\n",
      "(256,)\n",
      "Key umap has output shape <HDF5 dataset \"emb_256_batch_1024_k_20_metric_correlation_dist|iter_0.5\": shape (1024, 256), type \"<f4\">\n",
      "(256,)\n",
      "Key umap has output shape <HDF5 dataset \"emb_256_batch_1024_k_20_metric_euclidean_dist|iter_0.3\": shape (1024, 256), type \"<f4\">\n",
      "(256,)\n",
      "Key umap has output shape <HDF5 dataset \"emb_256_batch_1024_k_20_metric_euclidean_dist|iter_0.5\": shape (1024, 256), type \"<f4\">\n",
      "(256,)\n",
      "Key umap has output shape <HDF5 dataset \"emb_256_batch_1024_k_30_metric_correlation_dist|iter_0.3\": shape (1024, 256), type \"<f4\">\n",
      "(256,)\n",
      "Key umap has output shape <HDF5 dataset \"emb_256_batch_1024_k_30_metric_correlation_dist|iter_0.5\": shape (1024, 256), type \"<f4\">\n",
      "(256,)\n",
      "Key umap has output shape <HDF5 dataset \"emb_256_batch_1024_k_30_metric_euclidean_dist|iter_0.3\": shape (1024, 256), type \"<f4\">\n",
      "(256,)\n",
      "Key umap has output shape <HDF5 dataset \"emb_256_batch_1024_k_30_metric_euclidean_dist|iter_0.5\": shape (1024, 256), type \"<f4\">\n",
      "(256,)\n",
      "(1024, 512)\n",
      "Key umap has output shape <HDF5 dataset \"emb_256_batch_1024_k_20_metric_correlation_dist|iter_0.3\": shape (1024, 256), type \"<f4\">\n",
      "(256,)\n",
      "Key umap has output shape <HDF5 dataset \"emb_256_batch_1024_k_20_metric_correlation_dist|iter_0.5\": shape (1024, 256), type \"<f4\">\n",
      "(256,)\n",
      "Key umap has output shape <HDF5 dataset \"emb_256_batch_1024_k_20_metric_euclidean_dist|iter_0.3\": shape (1024, 256), type \"<f4\">\n",
      "(256,)\n",
      "Key umap has output shape <HDF5 dataset \"emb_256_batch_1024_k_20_metric_euclidean_dist|iter_0.5\": shape (1024, 256), type \"<f4\">\n",
      "(256,)\n",
      "Key umap has output shape <HDF5 dataset \"emb_256_batch_1024_k_30_metric_correlation_dist|iter_0.3\": shape (1024, 256), type \"<f4\">\n",
      "(256,)\n",
      "Key umap has output shape <HDF5 dataset \"emb_256_batch_1024_k_30_metric_correlation_dist|iter_0.5\": shape (1024, 256), type \"<f4\">\n",
      "(256,)\n",
      "Key umap has output shape <HDF5 dataset \"emb_256_batch_1024_k_30_metric_euclidean_dist|iter_0.3\": shape (1024, 256), type \"<f4\">\n",
      "(256,)\n",
      "Key umap has output shape <HDF5 dataset \"emb_256_batch_1024_k_30_metric_euclidean_dist|iter_0.5\": shape (1024, 256), type \"<f4\">\n",
      "(256,)\n"
     ]
    }
   ],
   "source": [
    "for fname in os.listdir(output_dir):\n",
    "    batch_path = os.path.join(output_dir, fname)\n",
    "\n",
    "    blob = h5py.File(batch_path, 'r')\n",
    "    \n",
    "    for key in blob.keys():\n",
    "        if isinstance(blob[key], h5py.Group):\n",
    "            for grp_key, val in blob[key].items():\n",
    "                print('Key {} has output shape {}'.format(key, blob[key][grp_key]))\n",
    "                print(blob[key][grp_key][0].shape)\n",
    "        else:\n",
    "            print(blob[key].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
