{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "from l3embedding.model import *\n",
    "from l3embedding.audio import pcm2float\n",
    "import umap\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sk7898/miniconda3/envs/l3embedding-new-cpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1238: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/sk7898/miniconda3/envs/l3embedding-new-cpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1255: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/sk7898/miniconda3/envs/l3embedding-new-cpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1204: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sk7898/miniconda3/envs/l3embedding-new-cpu/lib/python3.6/site-packages/librosa/filters.py:261: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  warnings.warn('Empty filters detected in mel frequency basis. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fmax: None\n",
      "<bound method Container.summary of <keras.engine.training.Model object at 0x2b695f61ed30>>\n"
     ]
    }
   ],
   "source": [
    "graph = tf.get_default_graph()\n",
    "weight_path = 'models/cnn_l3_melspec2_recent/model_best_valid_accuracy.h5'\n",
    "audio_model = load_embedding(weight_path, model_type = 'cnn_L3_melspec2', embedding_type = 'audio', \\\n",
    "                             pooling_type = 'short', kd_model=False, tgt_num_gpus = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(data, method, emb_length=None, neighbors=10, min_dist=0.3, iterations=300):\n",
    "    if len(data) == 0:\n",
    "        raise ValueError('Data is empty!')\n",
    "    if emb_length is None:\n",
    "        raise ValueError('Reduced embedding dimension was not provided!')\n",
    "\n",
    "    if method == 'umap':\n",
    "        embedding = umap.umap_.UMAP(n_neighbors=neighbors, min_dist=min_dist, \\\n",
    "                                    n_components=emb_length).fit_transform(data)\n",
    "    elif method == 'tsne':\n",
    "        embedding = TSNE(perplexity=neighbors, n_components=emb_length, n_iter=iterations).fit_transform(data)\n",
    "    else:\n",
    "        raise ValueError('Reduction method technique should be either `umap` or `tsne`!')\n",
    "    \n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(data_dir, reduced_emb_len, output_dir, reduction_method='umap', neighbors=10, min_dist=0.3, tsne_iter=300, \\\n",
    "                   batch_size=1024, random_state=20180123, start_batch_idx=None):\n",
    "\n",
    "    if data_dir == output_dir:\n",
    "        raise ValueError('Output path should not be same as Data path to avoid overwriting data files!')\n",
    "    random.seed(random_state)\n",
    "\n",
    "    batch = None\n",
    "    global graph\n",
    "    global audio_model\n",
    "    curr_batch_size = 0\n",
    "    batch_idx = 0\n",
    "    keys = ['audio']\n",
    "\n",
    "    for fname in os.listdir(data_dir):\n",
    "        print('Filename: ', fname)\n",
    "        batch_path = os.path.join(data_dir, fname)\n",
    "        blob_start_idx = 0\n",
    "        blob_end_idx = 0\n",
    "\n",
    "        blob = h5py.File(batch_path, 'r')\n",
    "        blob_size = len(blob['label'])\n",
    "\n",
    "        old_embeddings = np.zeros((blob_size, 512), dtype=np.float32)\n",
    "        embeddings = np.zeros((blob_size, reduced_emb_len), dtype=np.float32)\n",
    "        embedding_out_path = os.path.join(output_dir, fname)\n",
    "\n",
    "        if reduction_method == 'umap':\n",
    "            embedding_key = reduction_method + '_batch_' + str(batch_size) + '_k_' + str(neighbors) + '_dist_' + str(min_dist)\n",
    "        elif reduction_method == 'tsne':\n",
    "            embedding_key = reduction_method + '_batch_' + str(batch_size) + '_k_' + str(neighbors) + '_iter_' + str(tsne_iter)\n",
    "\n",
    "        while blob_start_idx < blob_size:\n",
    "            print('in while')\n",
    "            blob_end_idx = min(blob_start_idx + batch_size - curr_batch_size, blob_size)\n",
    "\n",
    "            # If we are starting from a particular batch, skip computing all of\n",
    "            # the prior batches\n",
    "            if start_batch_idx is None or batch_idx >= start_batch_idx:\n",
    "                if batch is None:\n",
    "                    batch = {k:blob[k][blob_start_idx:blob_end_idx]\n",
    "                             for k in keys}\n",
    "                else:\n",
    "                    for k in keys:\n",
    "                        batch[k] = np.concatenate([batch[k],\n",
    "                                                   blob[k][blob_start_idx:blob_end_idx]])\n",
    "\n",
    "            curr_batch_size += blob_end_idx - blob_start_idx\n",
    "\n",
    "            if blob_end_idx == blob_size:\n",
    "                blob.close()\n",
    "\n",
    "            if curr_batch_size == batch_size:\n",
    "                # If we are starting from a particular batch, skip yielding all\n",
    "                # of the prior batches\n",
    "                if start_batch_idx is None or batch_idx >= start_batch_idx:\n",
    "                    # Convert audio to float\n",
    "                    batch['audio'] = pcm2float(batch['audio'], dtype='float32')\n",
    "                    # Get the embedding layer output from the audio_model and flatten it to be treated as labels for the student audio model\n",
    "                    with graph.as_default():\n",
    "                        teacher_embedding = audio_model.predict(batch['audio'])\n",
    "\n",
    "                    old_embeddings[blob_start_idx:blob_end_idx, :] = teacher_embedding\n",
    "                    embeddings[blob_start_idx:blob_end_idx,:] = get_embedding(teacher_embedding, reduction_method, \\\n",
    "                                                                              emb_length=reduced_emb_len, neighbors=neighbors, \\\n",
    "                                                                              min_dist=min_dist, iterations=tsne_iter)\n",
    "\n",
    "                blob_start_idx = blob_end_idx\n",
    "                batch_idx += 1\n",
    "                curr_batch_size = 0\n",
    "                batch = None\n",
    "                print('One batch done')\n",
    "\n",
    "        with h5py.File(embedding_out_path, 'w') as f:\n",
    "            f.create_dataset(embedding_key, data=embeddings)\n",
    "            f.create_dataset('embedding', data=old_embeddings)\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename:  20180261_7_35.h5\n",
      "in while\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sk7898/miniconda3/envs/l3embedding-new-cpu/lib/python3.6/site-packages/umap/spectral.py:229: UserWarning: Embedding a total of 4 separate connected components using meta-embedding (experimental)\n",
      "  n_components\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One batch done\n",
      "Filename:  20180261_7_34.h5\n",
      "in while\n",
      "One batch done\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/scratch/sk7898/temp_data'\n",
    "reduced_emb_len = 256\n",
    "output_dir = '/scratch/sk7898/reduced_embeddings'\n",
    "\n",
    "data_generator(data_dir, reduced_emb_len, output_dir, reduction_method='umap', neighbors=10, min_dist=0.3, tsne_iter=300, \\\n",
    "               batch_size=1024, random_state=20180123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeysView(<HDF5 file \"20180261_7_35.h5\" (mode r)>)\n",
      "Key embedding has output shape (1024, 512)\n",
      "Key umap_batch_1024_k_10_dist_0.3 has output shape (1024, 256)\n",
      "KeysView(<HDF5 file \"20180261_7_34.h5\" (mode r)>)\n",
      "Key embedding has output shape (1024, 512)\n",
      "Key umap_batch_1024_k_10_dist_0.3 has output shape (1024, 256)\n"
     ]
    }
   ],
   "source": [
    "for fname in os.listdir(output_dir):\n",
    "    batch_path = os.path.join(output_dir, fname)\n",
    "\n",
    "    blob = h5py.File(batch_path, 'r')\n",
    "    \n",
    "    for key in blob.keys():\n",
    "          print('Key {} has output shape {}'.format(key, blob[key].shape)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
