{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import pytz\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from scipy.stats import rankdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_values(timestamp, timezone='America/New_York', \n",
    "                    map_2_hrs={str(2*i+k): value for k in range(2) for (i, value) in enumerate(range(12))}):\n",
    "    \n",
    "    dt = datetime.datetime.utcfromtimestamp(timestamp)\n",
    "    dt = pytz.UTC.localize(dt)\n",
    "    dt = dt.astimezone(pytz.timezone(timezone))\n",
    "    hour_of_the_day = dt.hour\n",
    "    day_of_the_week = dt.weekday()\n",
    "    week_of_the_year = dt.isocalendar()[1]\n",
    "    \n",
    "    # Get the 2 hour group id\n",
    "    # dt.hour = 0 and dt.hour = 1 gets mapped to hr_id = 0\n",
    "    # dt.hour = 2 and dt.hour = 3 gets mapped to hr_id = 1\n",
    "    #.\n",
    "    #.\n",
    "    # dt.hour = 22 and dt.hour = 23 gets mapped to hr_id = 11\n",
    "    hr_id = map_2_hrs[str(hour_of_the_day)]\n",
    "    \n",
    "    # Get combination of 2 hour id, day of the week and week of the year to enable groupby later\n",
    "    # This acts as a unique key for a 2-hr window\n",
    "    day_id = str(hr_id)+'-'+str(day_of_the_week)+'-'+str(week_of_the_year)\n",
    "    \n",
    "    return dict(hour_of_the_day=hour_of_the_day,\n",
    "                day_of_the_week=day_of_the_week,\n",
    "                week_of_the_year=week_of_the_year,\n",
    "                day_id=day_id,\n",
    "                hr_id=hr_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default parameter values are evaluated when the function definition is executed.\n",
    "# This means that the expression is evaluated once, when the function is defined, \n",
    "# and that that same ``pre-computed'' value is used for each call. \n",
    "\n",
    "def get_spl_frame_vector_old(spl_vector, spl_iterable=[4*k for k in range(20)],\n",
    "                             frame_keys=['frame_'+ str(i) for i in range(20)]):\n",
    "    \n",
    "    # From list of 80 values in spl_vector, get 20 values for 20 embedding frames by averaging 4 values\n",
    "    # Calculate the min and max of resulting 20 values to make calculation of min and max spl over 2 hr period easier\n",
    "    spl_frames = [0.25*sum([spl_vector[i+k] for k in range(4)]) for i in spl_iterable]\n",
    "    return dict({frame_keys[i]: value for (i, value) in enumerate(spl_frames)},\n",
    "                max_frame=max(spl_frames),\n",
    "                min_frame=min(spl_frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rel_loudness_with_scaling(df):\n",
    "    res = df.groupby(['day_id']).agg({'min_frame': np.min, 'max_frame': np.max}).reset_index()\n",
    "    final = pd.merge(df, res, on='day_id', how='outer', suffixes=('_emb', '_2_hr'))\n",
    "\n",
    "    # Get relative loudness of each frame using the min_frame_2_hr and max_frame_2_hr calculated above\n",
    "    for key in frame_keys:\n",
    "        final[key+'_rel_loudness'] = (final[key] - final['min_frame_2_hr'])/(final['max_frame_2_hr'] - final['min_frame_2_hr'])\n",
    "    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a string: spl_frames = ''.join(','.join(str(0.25*sum([spl_vector[i+k] for k in range(4)])) for i in spl_iterable))\n",
    "def get_spl_frame_vector(spl_vector, spl_iterable=[4*k for k in range(20)]):\n",
    "    \n",
    "    spl_frames = [0.25*sum([spl_vector[i+k] for k in range(4)]) for i in spl_iterable]\n",
    "    return dict({'spl_frames': spl_frames})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prob_sum(d, elements, count):\n",
    "    prob_sum = [d[i]/count.sum() for i in elements]\n",
    "    print('Sum of probs: ', np.array(prob_sum).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spl_prob(row, decimal_place=2):\n",
    "    d = {}\n",
    "    spl_frames = np.around(np.array(row['spl_frames']), decimals=decimal_place)\n",
    "    total_frames = len(spl_frames)\n",
    "    unique_elements, counts_elements = np.unique(spl_frames, return_counts=True)\n",
    "    d = {unique_elements[i]: counts_elements[i] for i in range(unique_elements.shape[0])}\n",
    "    res = [d[i]/total_frames for i in spl_frames]\n",
    "    #test_prob_sum(d, unique_elements, counts_elements)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_test(df):\n",
    "    print('Dataframe head:')\n",
    "    print(df.head())\n",
    "    print('---------------')\n",
    "    print('Example of unique probability values in the probability distribution over 2 hr window:')\n",
    "    print(np.unique(df.iloc[0]['prob_spl_2_hr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rel_loudness_probs(feats_path, indices_path):\n",
    "    indices = h5py.File(indices_path)\n",
    "    blob = h5py.File(feats_path)\n",
    "\n",
    "    # Get the timestamp from the feature file\n",
    "    ts = blob['openl3']['timestamp']\n",
    "\n",
    "    # Not used as of now\n",
    "    feats = blob['openl3']['openl3']\n",
    "\n",
    "    # Get the spl_vector from the indices file\n",
    "    spl_vecs = indices['recording_index']['spl_vector']\n",
    "\n",
    "    assert feats.shape[0] == ts.shape[0] == spl_vecs.shape[0]\n",
    "\n",
    "    # Get the spl avg value of 4 consecutive values from spl_vector\n",
    "    spl_arr = np.apply_along_axis(get_spl_frame_vector, 1, spl_vecs)\n",
    "\n",
    "    # Apply get_time_values() to each element of the timestamp array \n",
    "    dt_vectorize = np.vectorize(get_time_values)\n",
    "    t_arr = dt_vectorize(ts)\n",
    "\n",
    "    # Convert the dicts obtained above into dataframe and combine them to make aggregation easier\n",
    "    t_df = pd.DataFrame(list(t_arr))\n",
    "    spl_df = pd.DataFrame(list(spl_arr)) \n",
    "    df = pd.concat([t_df, spl_df], axis=1)\n",
    "    \n",
    "    res = df.groupby(['day_id'], as_index = False).agg({'spl_frames': 'sum'}).reset_index() \n",
    "    res['prob_spl_2_hr'] = res.apply(lambda row : get_spl_prob(row), axis = 1)\n",
    "    final = pd.merge(df, res, on='day_id', how='outer', suffixes=('_emb_str', '_2_hr_str'))\n",
    "    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe head:\n",
      "   day_id  day_of_the_week  hour_of_the_day  hr_id  week_of_the_year  \\\n",
      "0  8-2-42                2               16      8                42   \n",
      "1  8-2-42                2               16      8                42   \n",
      "2  8-2-42                2               16      8                42   \n",
      "3  8-2-42                2               16      8                42   \n",
      "4  8-2-42                2               16      8                42   \n",
      "\n",
      "                                  spl_frames_emb_str  index  \\\n",
      "0  [62.797499656677246, 65.18499946594238, 62.577...    720   \n",
      "1  [65.99249839782715, 67.80750274658203, 68.3674...    720   \n",
      "2  [62.71750068664551, 62.96500015258789, 63.3200...    720   \n",
      "3  [62.14999961853027, 66.05249977111816, 62.5624...    720   \n",
      "4  [64.3400011062622, 64.84749984741211, 65.59249...    720   \n",
      "\n",
      "                                 spl_frames_2_hr_str  \\\n",
      "0  [62.797499656677246, 65.18499946594238, 62.577...   \n",
      "1  [62.797499656677246, 65.18499946594238, 62.577...   \n",
      "2  [62.797499656677246, 65.18499946594238, 62.577...   \n",
      "3  [62.797499656677246, 65.18499946594238, 62.577...   \n",
      "4  [62.797499656677246, 65.18499946594238, 62.577...   \n",
      "\n",
      "                                       prob_spl_2_hr  \n",
      "0  [0.0029850746268656717, 0.0007462686567164179,...  \n",
      "1  [0.0029850746268656717, 0.0007462686567164179,...  \n",
      "2  [0.0029850746268656717, 0.0007462686567164179,...  \n",
      "3  [0.0029850746268656717, 0.0007462686567164179,...  \n",
      "4  [0.0029850746268656717, 0.0007462686567164179,...  \n",
      "---------------\n",
      "Example of unique probability values in the probability distribution over 2 hr window:\n",
      "[0.00074627 0.00149254 0.00223881 0.00298507 0.00373134 0.00447761\n",
      " 0.00522388 0.00671642]\n"
     ]
    }
   ],
   "source": [
    "feats_path = '/beegfs/work/sonyc/features/openl3/2017/sonycnode-b827ebefb215.sonyc_features_openl3.h5'\n",
    "indices_path = '/beegfs/work/sonyc/indices/2017/'+ os.path.basename(feats_path).replace('features_openl3', 'recording_index')\n",
    "\n",
    "final = get_rel_loudness_probs(feats_path, indices_path)\n",
    "pretty_print_test(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
