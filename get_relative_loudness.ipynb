{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import pytz\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_values(timestamp, timezone='America/New_York'):\n",
    "    \n",
    "    dt = datetime.datetime.utcfromtimestamp(timestamp)\n",
    "    dt = pytz.UTC.localize(dt)\n",
    "    dt = dt.astimezone(pytz.timezone(timezone))\n",
    "    hour_of_the_day = dt.hour\n",
    "    day_of_the_week = dt.weekday()\n",
    "    week_of_the_year = dt.isocalendar()[1]\n",
    "    \n",
    "    # Get the 2 hour group id\n",
    "    # dt.hour = 0 and dt.hour = 1 gets mapped to hr_id = 0\n",
    "    # dt.hour = 2 and dt.hour = 3 gets mapped to hr_id = 1\n",
    "    #.\n",
    "    #.\n",
    "    # dt.hour = 22 and dt.hour = 23 gets mapped to hr_id = 11\n",
    "    hr_id = map_2_hrs[str(hour_of_the_day)]\n",
    "    \n",
    "    # Get combination of 2 hour id, day of the week and week of the year to enable groupby later\n",
    "    # This acts as a unique key for a 2-hr window\n",
    "    day_id = str(hr_id)+'-'+str(day_of_the_week)+'-'+str(week_of_the_year)\n",
    "    \n",
    "    return dict(hour_of_the_day=hour_of_the_day,\n",
    "                day_of_the_week=day_of_the_week,\n",
    "                week_of_the_year=week_of_the_year,\n",
    "                day_id=day_id,\n",
    "                hr_id=hr_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spl_frame_vector(spl_vector):\n",
    "    \n",
    "    # From list of 80 values in spl_vector, get 20 values for 20 embedding frames by averaging 4 values\n",
    "    # Calculate the min and max of resulting 20 values to make calculation of min and max spl over 2 hr period easier\n",
    "    spl_frames = [0.25*sum([spl_vector[i+k] for k in range(4)]) for i in spl_iterable]\n",
    "    return dict({frame_keys[i]: value for (i, value) in enumerate(spl_frames)},\n",
    "                max_frame=max(spl_frames),\n",
    "                min_frame=min(spl_frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_test(map_2_hrs, frame_keys, df, final):\n",
    "    print('Keys for 2 hr groups:')\n",
    "    print(map_2_hrs)\n",
    "    print('---------------')\n",
    "    print('Keys for spl/frame: ')\n",
    "    print(frame_keys)\n",
    "    print('---------------')\n",
    "    print('Dataframe before aggregating min and max over spl values:')\n",
    "    print(df.head())\n",
    "    print('---------------')\n",
    "    print('Dataframe after calculating the relative loudness per frame:')\n",
    "    print(final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_path = '/beegfs/work/sonyc/features/openl3/2017/sonycnode-b827ebefb215.sonyc_features_openl3.h5'\n",
    "indices_path = '/beegfs/work/sonyc/indices/2017/'+ os.path.basename(feats_path).replace('features_openl3', 'recording_index')\n",
    "indices = h5py.File(indices_path)\n",
    "blob = h5py.File(feats_path)\n",
    " \n",
    "# Get the timestamp from the feature file\n",
    "ts = blob['openl3']['timestamp']\n",
    "\n",
    "# Not used as of now\n",
    "feats = blob['openl3']['openl3']\n",
    "\n",
    "# Get the spl_vector from the indices file\n",
    "spl_vecs = indices['recording_index']['spl_vector']\n",
    "\n",
    "assert feats.shape[0] == ts.shape[0] == spl_vecs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 mappings/list to make list comprehensions easier\n",
    "map_2_hrs = {str(2*i+k): value for k in range(2) for (i, value) in enumerate(range(12))}\n",
    "spl_iterable = [4*k for k in range(20)]\n",
    "frame_keys = ['frame_'+ str(i) for i in range(20)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the spl avg value of 4 consecutive values from spl_vector\n",
    "spl_arr = np.apply_along_axis(get_spl_frame_vector, 1, spl_vecs)\n",
    "\n",
    "# Apply get_time_values() to each element of the timestamp array \n",
    "dt_vectorize = np.vectorize(get_time_values)\n",
    "t_arr = dt_vectorize(ts)\n",
    "\n",
    "# Convert the dicts obtained above into dataframe and combine them to make aggregation easier\n",
    "t_df = pd.DataFrame(list(t_arr))\n",
    "spl_df = pd.DataFrame(list(spl_arr)) \n",
    "df = pd.concat([t_df, spl_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the min and max spl values over 2 hr window\n",
    "res = df.groupby(['day_id']).agg({'min_frame': np.min, 'max_frame': np.max}).reset_index()\n",
    "final = pd.merge(df, res, on='day_id', how='outer', suffixes=('_emb', '_2_hr'))\n",
    "\n",
    "# Get relative loudness of each frame using the min_frame_2_hr and max_frame_2_hr calculated above\n",
    "for key in frame_keys:\n",
    "    final[key+'_rel_loudness'] = (final[key] - final['min_frame_2_hr'])/(final['max_frame_2_hr'] - final['min_frame_2_hr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys for 2 hr groups:\n",
      "{'0': 0, '2': 1, '4': 2, '6': 3, '8': 4, '10': 5, '12': 6, '14': 7, '16': 8, '18': 9, '20': 10, '22': 11, '1': 0, '3': 1, '5': 2, '7': 3, '9': 4, '11': 5, '13': 6, '15': 7, '17': 8, '19': 9, '21': 10, '23': 11}\n",
      "---------------\n",
      "Keys for spl/frame: \n",
      "['frame_0', 'frame_1', 'frame_2', 'frame_3', 'frame_4', 'frame_5', 'frame_6', 'frame_7', 'frame_8', 'frame_9', 'frame_10', 'frame_11', 'frame_12', 'frame_13', 'frame_14', 'frame_15', 'frame_16', 'frame_17', 'frame_18', 'frame_19']\n",
      "---------------\n",
      "Dataframe before aggregating min and max over spl values:\n",
      "   day_id  day_of_the_week  hour_of_the_day  hr_id  week_of_the_year  \\\n",
      "0  8-2-42                2               16      8                42   \n",
      "1  8-2-42                2               16      8                42   \n",
      "2  8-2-42                2               16      8                42   \n",
      "3  8-2-42                2               16      8                42   \n",
      "4  8-2-42                2               16      8                42   \n",
      "\n",
      "     frame_0    frame_1   frame_10   frame_11   frame_12    ...      \\\n",
      "0  62.797500  65.184999  64.592499  64.950000  64.280000    ...       \n",
      "1  65.992498  67.807503  67.660000  67.122501  66.255001    ...       \n",
      "2  62.717501  62.965000  64.887503  64.505001  64.107499    ...       \n",
      "3  62.150000  66.052500  63.315000  63.330000  62.457500    ...       \n",
      "4  64.340001  64.847500  65.010001  64.690001  64.477500    ...       \n",
      "\n",
      "     frame_2    frame_3    frame_4    frame_5    frame_6    frame_7  \\\n",
      "0  62.577499  63.160000  63.644999  64.000001  63.775002  64.584999   \n",
      "1  68.367498  69.279999  68.760000  69.180002  70.100000  68.410002   \n",
      "2  63.320001  63.590001  62.675000  63.215000  63.952500  65.049999   \n",
      "3  62.562499  62.055000  61.492500  61.679999  62.475000  62.784999   \n",
      "4  65.592499  65.302498  64.982500  65.947500  66.257500  66.177502   \n",
      "\n",
      "     frame_8    frame_9  max_frame  min_frame  \n",
      "0  65.732500  65.655001  66.112502  62.577499  \n",
      "1  68.370001  69.362499  70.100000  65.717501  \n",
      "2  65.242500  64.752499  65.242500  62.675000  \n",
      "3  62.557500  62.945000  66.052500  61.492500  \n",
      "4  65.549999  66.365000  66.365000  62.462500  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "---------------\n",
      "Dataframe after calculating the relative loudness per frame:\n",
      "   day_id  day_of_the_week  hour_of_the_day  hr_id  week_of_the_year  \\\n",
      "0  8-2-42                2               16      8                42   \n",
      "1  8-2-42                2               16      8                42   \n",
      "2  8-2-42                2               16      8                42   \n",
      "3  8-2-42                2               16      8                42   \n",
      "4  8-2-42                2               16      8                42   \n",
      "\n",
      "     frame_0    frame_1   frame_10   frame_11   frame_12  \\\n",
      "0  62.797500  65.184999  64.592499  64.950000  64.280000   \n",
      "1  65.992498  67.807503  67.660000  67.122501  66.255001   \n",
      "2  62.717501  62.965000  64.887503  64.505001  64.107499   \n",
      "3  62.150000  66.052500  63.315000  63.330000  62.457500   \n",
      "4  64.340001  64.847500  65.010001  64.690001  64.477500   \n",
      "\n",
      "           ...            frame_10_rel_loudness  frame_11_rel_loudness  \\\n",
      "0          ...                         0.253399               0.274765   \n",
      "1          ...                         0.436725               0.404602   \n",
      "2          ...                         0.271030               0.248170   \n",
      "3          ...                         0.177051               0.177947   \n",
      "4          ...                         0.278351               0.259226   \n",
      "\n",
      "   frame_12_rel_loudness  frame_13_rel_loudness  frame_14_rel_loudness  \\\n",
      "0               0.234723               0.317197               0.344240   \n",
      "1               0.352757               0.369491               0.363066   \n",
      "2               0.224414               0.262961               0.245181   \n",
      "3               0.125803               0.147766               0.151502   \n",
      "4               0.246526               0.179441               0.189751   \n",
      "\n",
      "   frame_15_rel_loudness  frame_16_rel_loudness  frame_17_rel_loudness  \\\n",
      "0               0.228597               0.182131               0.221126   \n",
      "1               0.328253               0.445839               0.382041   \n",
      "2               0.244434               0.188107               0.282235   \n",
      "3               0.181981               0.210967               0.161363   \n",
      "4               0.150456               0.203646               0.126102   \n",
      "\n",
      "   frame_18_rel_loudness  frame_19_rel_loudness  \n",
      "0               0.203944               0.140146  \n",
      "1               0.320634               0.356343  \n",
      "2               0.236217               0.158972  \n",
      "3               0.074854               0.135515  \n",
      "4               0.177798               0.173017  \n",
      "\n",
      "[5 rows x 49 columns]\n"
     ]
    }
   ],
   "source": [
    "pretty_print_test(map_2_hrs, frame_keys, df, final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How should we bin the rel_loudness values to find the probability distribution?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
