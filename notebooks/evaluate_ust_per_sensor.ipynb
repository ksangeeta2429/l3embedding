{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/sk7898/l3embedding/classifier/sonyc_ust\n"
     ]
    }
   ],
   "source": [
    "%cd '/scratch/sk7898/l3embedding/classifier/sonyc_ust'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import os\n",
    "import random\n",
    "import csv\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import resampy\n",
    "import tensorflow as tf\n",
    "import librosa\n",
    "import keras\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import load_model\n",
    "from matplotlib import cm\n",
    "from metrics import parse_coarse_prediction, micro_averaged_auprc, macro_averaged_auprc, evaluate_df\n",
    "from classify import load_embeddings, predict_mil, construct_mlp_mil\n",
    "# New modules: oyaml and pandas\n",
    "import oyaml as yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sensor_with_meta(version, sensor_df, meta_df):\n",
    "    meta_df['sensor_name'] = meta_df['node_id'].apply(lambda x: x[10:-6])\n",
    "    s_in_test = sensor_df[sensor_df['split'] == 'test']['sensor_name'].unique().tolist()\n",
    "    sensors = meta_df[meta_df['sensor_name'].isin(s_in_test)]['sensor_name']\n",
    "    return sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_output(y_pred, output_path, test_file_list, annotation_data, label_mode, taxonomy):\n",
    "    \n",
    "    coarse_fine_labels = [[\"{}-{}_{}\".format(coarse_id, fine_id, fine_label)\n",
    "                           for fine_id, fine_label in fine_dict.items()]\n",
    "                          for coarse_id, fine_dict in taxonomy['fine'].items()]\n",
    "        \n",
    "    full_fine_target_labels = [fine_label for fine_list in coarse_fine_labels\n",
    "                               for fine_label in fine_list]\n",
    "        \n",
    "    coarse_target_labels = [\"_\".join([str(k), v])\n",
    "                            for k, v in taxonomy['coarse'].items()]\n",
    "    \n",
    "    annotation = annotation_data.sort_values('audio_filename')[['split', 'sensor_id', 'audio_filename']].drop_duplicates()\n",
    "    annotation = annotation[annotation['audio_filename'].isin(test_file_list)]\n",
    "    split_list = annotation['split'].tolist()\n",
    "    sensor_list = annotation['sensor_id'].tolist()\n",
    "    \n",
    "    with open(output_path, 'w') as f:\n",
    "        csvwriter = csv.writer(f)\n",
    "\n",
    "        # Write fields\n",
    "        fields = [\"split\", \"sensor_id\", \"audio_filename\"] + full_fine_target_labels + coarse_target_labels\n",
    "        csvwriter.writerow(fields)\n",
    "\n",
    "        # Write results for each file to CSV\n",
    "        for split, sid, filename, y in zip(split_list, sensor_list, test_file_list, y_pred):\n",
    "            row = [split, sid, filename]\n",
    "\n",
    "            if label_mode == \"fine\":\n",
    "                fine_values = []\n",
    "                coarse_values = [0 for _ in range(len(coarse_target_labels))]\n",
    "                coarse_idx = 0\n",
    "                fine_idx = 0\n",
    "                for coarse_label, fine_label_list in zip(coarse_target_labels,\n",
    "                                                         coarse_fine_labels):\n",
    "                    for fine_label in fine_label_list:\n",
    "                        if 'X' in fine_label.split('_')[0].split('-')[1]:\n",
    "                            # Put a 0 for other, since the baseline doesn't\n",
    "                            # account for it\n",
    "                            fine_values.append(0.0)\n",
    "                            continue\n",
    "\n",
    "                        # Append the next fine prediction\n",
    "                        fine_values.append(y[fine_idx])\n",
    "\n",
    "                        # Add coarse level labels corresponding to fine level\n",
    "                        # predictions. Obtain by taking the maximum from the\n",
    "                        # fine level labels\n",
    "                        coarse_values[coarse_idx] = max(coarse_values[coarse_idx],\n",
    "                                                        y[fine_idx])\n",
    "                        fine_idx += 1\n",
    "                    coarse_idx += 1\n",
    "\n",
    "                row += fine_values + coarse_values\n",
    "                \n",
    "            else:\n",
    "                # Add placeholder values for fine level\n",
    "                row += [0.0 for _ in range(len(full_fine_target_labels))]\n",
    "                # Add coarse level labels\n",
    "                row += list(y)\n",
    "\n",
    "            csvwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_ground_truth_split(ann_df, aggregate=True, valid_sensor_ids=None, split_path=None, split=None):\n",
    "    \n",
    "    if split and not valid_sensor_ids:\n",
    "        gt_df = ann_df[(ann_df[\"annotator_id\"] > 0) & (ann_df['split'] == split)]\n",
    "        #gt_df = ann_df[(ann_df[\"annotator_id\"] == 0) & (ann_df['split'] == split)]\n",
    "    elif split and valid_sensor_ids:\n",
    "        gt_df = ann_df[(ann_df[\"annotator_id\"] == 0) & (ann_df['split'] == split) & (ann_df['sensor_id'].isin(valid_sensor_ids))]\n",
    "    else:\n",
    "        gt_df = ann_df[ann_df[\"annotator_id\"] == 0]\n",
    "    \n",
    "    if aggregate:\n",
    "        gt_df = gt_df.groupby(\"audio_filename\", group_keys=False).max()\n",
    "    \n",
    "    gt_df.reset_index(inplace=True)\n",
    "    if 'index' in gt_df.keys():\n",
    "        gt_df = gt_df.drop(columns=['index'])\n",
    "    return gt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_ground_truth(annotation_path, yaml_path, valid_sensor_ids=None, split_path=None, split=None):\n",
    "\n",
    "    # Create dictionary to parse tags\n",
    "    with open(yaml_path, 'r') as stream:\n",
    "        yaml_dict = yaml.load(stream, Loader=yaml.Loader)\n",
    "\n",
    "    # Load CSV file into a Pandas DataFrame.\n",
    "    ann_df = pd.read_csv(annotation_path)\n",
    "    gt_df = filter_ground_truth_split(ann_df,\n",
    "                                      valid_sensor_ids=valid_sensor_ids,\n",
    "                                      split_path=split_path,\n",
    "                                      split=split)\n",
    "\n",
    "    # Rename coarse columns.\n",
    "    coarse_dict = yaml_dict[\"coarse\"]\n",
    "    coarse_renaming = {\n",
    "        \"_\".join([str(c), coarse_dict[c], \"presence\"]): str(c)\n",
    "        for c in coarse_dict}\n",
    "    gt_df = gt_df.rename(columns=coarse_renaming)\n",
    "\n",
    "    # Collect tag names as strings and map them to mixed (coarse-fine) ID pairs.\n",
    "    # The \"mixed key\" is a hyphenation of the coarse ID and fine ID.\n",
    "    fine_dict = {}\n",
    "    for coarse_id in yaml_dict[\"fine\"]:\n",
    "        for fine_id in yaml_dict[\"fine\"][coarse_id]:\n",
    "            mixed_key = \"-\".join([str(coarse_id), str(fine_id)])\n",
    "            fine_dict[mixed_key] = yaml_dict[\"fine\"][coarse_id][fine_id]\n",
    "\n",
    "    # Rename fine columns.\n",
    "    fine_renaming = {\"_\".join([k, fine_dict[k], \"presence\"]): k\n",
    "        for k in fine_dict}\n",
    "    gt_df = gt_df.rename(columns=fine_renaming)\n",
    "\n",
    "    # Loop over coarse tags.\n",
    "    n_samples = len(gt_df)\n",
    "    coarse_dict = yaml_dict[\"coarse\"]\n",
    "    for coarse_id in yaml_dict[\"coarse\"]:\n",
    "        # Construct incomplete fine tag by appending -X to the coarse tag.\n",
    "        incomplete_tag = str(coarse_id) + \"-X\"\n",
    "\n",
    "        # If the incomplete tag is not in the prediction, append a column of zeros.\n",
    "        # This is the case e.g. for coarse ID 7 (\"dogs\") which has a single\n",
    "        # fine-level tag (\"7-1_dog-barking-whining\") and thus no incomplete\n",
    "        # tag 7-X.\n",
    "        if incomplete_tag not in gt_df.columns:\n",
    "            gt_df[incomplete_tag] = np.zeros((n_samples,)).astype('int')\n",
    "\n",
    "    gt_df = gt_df.sort_values('audio_filename')\n",
    "\n",
    "    gt_df.reset_index(inplace=True)\n",
    "    if 'index' in gt_df.keys():\n",
    "        gt_df = gt_df.drop(columns=['index'])\n",
    "\n",
    "    # Return output in DataFrame format.\n",
    "    return gt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_sensor_df(gt_df, pred_df, mode, yaml_dict, split=None):\n",
    "    \n",
    "    dicts = {}\n",
    "    split = split if split else 'validate'\n",
    "    sids = pred_df[pred_df['split'] == split]['sensor_id'].unique().tolist()\n",
    "        \n",
    "    for sid in sids:\n",
    "        gt = gt_df[(gt_df['split'] == split) & (gt_df['sensor_id'] == sid)]\n",
    "        pred = pred_df[(pred_df['split'] == split) & (pred_df['sensor_id'] == sid)]\n",
    "        gt = gt.drop(columns=['split', 'sensor_id'])\n",
    "        pred = pred.drop(columns=['split', 'sensor_id'])\n",
    "        dicts[sid] = evaluate_df(gt, pred, mode, yaml_dict)\n",
    "    return dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(prediction_path, annotation_path, yaml_path, mode, \n",
    "             valid_sensor_ids=None,\n",
    "             split_path=None, \n",
    "             per_sensor=False, \n",
    "             split=None):\n",
    "\n",
    "    with open(yaml_path, 'r') as stream:\n",
    "        yaml_dict = yaml.load(stream, Loader=yaml.Loader)\n",
    "\n",
    "    # Parse ground truth.\n",
    "    gt_df = parse_ground_truth(annotation_path, yaml_path,\n",
    "                               valid_sensor_ids=valid_sensor_ids,\n",
    "                               split_path=split_path,\n",
    "                               split=split)\n",
    "\n",
    "    # Parse predictions.\n",
    "    if mode == \"fine\":\n",
    "        pred_df = parse_fine_prediction(prediction_path, yaml_path)\n",
    "    elif mode == \"coarse\":\n",
    "        pred_df = parse_coarse_prediction(prediction_path, yaml_path)\n",
    "    \n",
    "    flist = [value for value in gt_df['audio_filename'].unique().tolist() \n",
    "             if value in pred_df['audio_filename'].unique().tolist()] \n",
    "    pred_df = pred_df[pred_df['audio_filename'].isin(flist)]\n",
    "    gt_df = gt_df[gt_df['audio_filename'].isin(flist)]\n",
    "\n",
    "    if per_sensor:\n",
    "        return evaluate_sensor_df(gt_df, pred_df, mode, yaml_dict, split=split)\n",
    "    else:\n",
    "        return evaluate_df(gt_df, pred_df, mode, yaml_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'v0.4' #'v2.2'\n",
    "label_mode = 'coarse'\n",
    "\n",
    "if version == 'v2.2':\n",
    "    annotation_path = '/scratch/work/sonyc/sonyc/ust/annotations/latest/annotations_w_test_anns.csv'\n",
    "else:\n",
    "    annotation_path = '/scratch/work/sonyc/sonyc/ust/annotations/{}/annotations.csv'.format(version)\n",
    "\n",
    "embs_version = version if version == 'v2.2' else ''\n",
    "embs_dir = '/scratch/sk7898/sonyc_output/embeddings'\n",
    "taxonomy_path = '/scratch/work/sonyc/sonyc/ust/annotations/{}/dcase-ust-taxonomy.yaml'.format(version)\n",
    "emb_dir = os.path.join(embs_dir, embs_version, 'features/sonyc_ust/l3/melSpec_20200304183233_48000_256_242_2048')\n",
    "cls_path = os.path.join(embs_dir, 'classifier/sonyc_ust/mil/melSpec_20200304183233_48000_256_242_2048/0_0/results')\n",
    "output_path = os.path.join(cls_path, 'output_{}.csv'.format(version))\n",
    "scaler_path = os.path.join(cls_path, 'stdizer.pkl')\n",
    "\n",
    "meta_df = pd.read_csv('/scratch/sk7898/l3embedding/notebooks/data/node_meta.csv')\n",
    "sensor_df = pd.read_csv('/scratch/sk7898/l3embedding/notebooks/data/sensor_split_ids_{}.csv'.format(version))\n",
    "annotation_data = pd.read_csv(annotation_path).sort_values('audio_filename')\n",
    "with open(taxonomy_path, 'r') as f:\n",
    "    taxonomy = yaml.load(f, Loader=yaml.Loader)\n",
    "                                    \n",
    "file_list = annotation_data.sort_values('audio_filename')['audio_filename'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'test'\n",
    "lst = annotation_data[annotation_data['split'] == split].sort_values('audio_filename')['audio_filename'].unique().tolist()\n",
    "file_list = lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict (with model for coarse labels) on test data and save the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_path):\n",
    "    embeddings = load_embeddings(file_list, emb_dir)\n",
    "        \n",
    "    if os.path.exists(scaler_path):\n",
    "        print('Found Standardizer!')\n",
    "        scaler = pk.load(open(scaler_path,'rb'), encoding='utf-8')\n",
    "        embeddings = [scaler.transform(emb_grp) for emb_grp in embeddings]\n",
    "        \n",
    "    X = np.array(embeddings)\n",
    "    _, num_frames, emb_size = X.shape\n",
    "\n",
    "    num_classes = 8\n",
    "    model_weight_file = os.path.join(cls_path, 'model_best.h5')\n",
    "    model = construct_mlp_mil(num_frames,\n",
    "                              emb_size,\n",
    "                              num_classes,\n",
    "                              num_hidden_layers=0,\n",
    "                              hidden_layer_size=0)\n",
    "\n",
    "    model.load_weights(model_weight_file)\n",
    "            \n",
    "    pred = model.predict(X)\n",
    "\n",
    "    # Discard auxilliary predictions\n",
    "    if type(pred) == list:\n",
    "        pred = pred[0]\n",
    "\n",
    "    pred.tolist()\n",
    "    write_to_output(pred, output_path, file_list, annotation_data, label_mode, taxonomy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the output file saved above to evaluate the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.read_csv(output_path)\n",
    "\n",
    "df_dicts = evaluate(\n",
    "                    output_path,\n",
    "                    annotation_path,\n",
    "                    taxonomy_path, \n",
    "                    mode=label_mode,\n",
    "                    valid_sensor_ids=None,\n",
    "                    per_sensor=True,\n",
    "                    split=split\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "class_metrics = {}\n",
    "\n",
    "for sensor, df_dict in df_dicts.items():\n",
    "    metrics[sensor] = {}\n",
    "    class_metrics[sensor] = {}\n",
    "    micro_auprc, eval_df = micro_averaged_auprc(df_dict, return_df=True)\n",
    "    macro_auprc, class_auprc = macro_averaged_auprc(df_dict, return_classwise=True)\n",
    "\n",
    "    # Get index of first threshold that is at least 0.5\n",
    "    thresh_0pt5_idx = (eval_df['threshold'] >= 0.5).to_numpy().nonzero()[0][0]\n",
    "\n",
    "    metrics[sensor][\"sensor_name\"] = sensor_df[sensor_df['sensor_id'] == sensor]['sensor_name'].tolist()[0]\n",
    "    metrics[sensor][\"micro_auprc\"] = micro_auprc\n",
    "    metrics[sensor][\"micro_f1\"] = eval_df[\"F\"][thresh_0pt5_idx]\n",
    "    metrics[sensor][\"macro_auprc\"] = macro_auprc\n",
    "    \n",
    "    for coarse_id, auprc in class_auprc.items():\n",
    "        coarse_name = taxonomy['coarse'][int(coarse_id)]\n",
    "        class_metrics[sensor][coarse_name] = auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame.from_dict(metrics, orient='index')\n",
    "result['sensor_id'] = result.index.tolist()\n",
    "\n",
    "classwise_result = pd.DataFrame.from_dict(class_metrics, orient='index')\n",
    "classwise_result['sensor_id'] = classwise_result.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'classwise' #''\n",
    "result, classwise_result = None, None\n",
    "save_df = False\n",
    "save_pred = '/scratch/sk7898/l3embedding/notebooks/data/per_sensor_{}_{}.csv'.format(split, version)\n",
    "save_classwise_pred = '/scratch/sk7898/l3embedding/notebooks/data/classwise_per_sensor_{}_{}.csv'.format(split, version)\n",
    "\n",
    "if save_df:\n",
    "    result.to_csv(save_pred, index=False)\n",
    "    classwise_result.to_csv(save_classwise_pred, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SONYC_UST v2\n",
    "Sensors: 56\n",
    "\n",
    "### SONYC_UST v1\n",
    "Sensors: 0, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 6})\n",
    "metric_pdf_path = '/scratch/sk7898/l3embedding/notebooks/data/metric_{}.pdf'.format(version)\n",
    "cls_dist_path = '/scratch/sk7898/l3embedding/notebooks/data/cls_dist_{}.pdf'.format(version)\n",
    "version = 'v0.4' #'v2.2'\n",
    "modes = ['classwise', 'overall']\n",
    "coarse_columns = ['1_engine_presence', '2_machinery-impact_presence', \n",
    "                  '3_non-machinery-impact_presence', '4_powered-saw_presence', \n",
    "                  '5_alert-signal_presence', '6_music_presence',\n",
    "                  '7_human-voice_presence', '8_dog_presence'\n",
    "                 ]\n",
    "sensors = get_sensor_with_meta(version, sensor_df, meta_df)\n",
    "\n",
    "# Get the train and test class distribution\n",
    "cdist = {}\n",
    "for split in ['train', 'test']:\n",
    "    if split == 'train':\n",
    "        data = annotation_data[annotation_data['split'] == 'train']\n",
    "        data = data.groupby(\"audio_filename\", group_keys=False).max()\n",
    "    elif split == 'test':\n",
    "        data = annotation_data[(annotation_data['split'] == 'test') & (annotation_data['annotator_id'] == 0)]\n",
    "    \n",
    "    c_arr = [np.count_nonzero(np.array(data[cls])) for cls in coarse_columns]\n",
    "    cdist[split] = [cnt/sum(c_arr) for cnt in c_arr]\n",
    "\n",
    "cols = [c[2:-9] for c in coarse_columns]\n",
    "cls_df = pd.DataFrame.from_dict(cdist, orient='index', columns=cols)\n",
    "\n",
    "with PdfPages(cls_dist_path) as pdf:\n",
    "    # Plot the 3 graphs for each sensor in pdf\n",
    "    for sensor_name in sensors:\n",
    "        fig, ax = plt.subplots()\n",
    "        sensor_meta = meta_df[meta_df['sensor_name'] == sensor_name]\n",
    "        sid = sensor_df[sensor_df['sensor_name'] == sensor_name]['sensor_id'].unique()[0]\n",
    "        pdf.attach_note(\"Sensor: {}\".format(sid)) \n",
    "        pdf.attach_note(\"Metadata: {}\".format(dict(sensor_meta.iloc[0][~pd.isna(sensor_meta.iloc[0])]))) \n",
    "        \n",
    "        # Plot the data distribution\n",
    "        data = annotation_data[(annotation_data['split'] == 'test') & \n",
    "                               (annotation_data['annotator_id'] == 0) & \n",
    "                               (annotation_data['sensor_id'] == sid)]\n",
    "\n",
    "        c_arr = [np.count_nonzero(np.array(data[cls])) for cls in coarse_columns]\n",
    "        cls_df.loc[sid] = [cnt/sum(c_arr) for cnt in c_arr]\n",
    "\n",
    "        cdist = cls_df.loc[['train', 'test', sid]]\n",
    "        cdist.T.plot.bar(ax=ax)\n",
    "        plt.title('Class Distribution')  \n",
    "        plt.tight_layout()\n",
    "        pdf.savefig()\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "        plt.close()\n",
    "        \n",
    "with PdfPages(metric_pdf_path) as pdf:\n",
    "    # Plot the 3 graphs for each sensor in pdf\n",
    "    for sensor_name in sensors:\n",
    "        fig = plt.figure()\n",
    "        sensor_meta = meta_df[meta_df['sensor_name'] == sensor_name]\n",
    "        sid = sensor_df[sensor_df['sensor_name'] == sensor_name]['sensor_id'].unique()[0]\n",
    "        pdf.attach_note(\"Sensor: {}\".format(sid)) \n",
    "        pdf.attach_note(\"Metadata: {}\".format(dict(sensor_meta.iloc[0][~pd.isna(sensor_meta.iloc[0])]))) \n",
    "   \n",
    "        for mode in modes:\n",
    "            # classwise performance \n",
    "            if mode == 'classwise':\n",
    "                ax = fig.add_subplot(211)\n",
    "                plot_title = 'Classwise AUPRC on Test Data'\n",
    "                test1 =  pd.read_csv(save_classwise_pred) if classwise_result is None else classwise_result\n",
    "                metrics = test1.columns[test1.columns != 'sensor_id']\n",
    "            # overall performance \n",
    "            else:\n",
    "                ax = fig.add_subplot(212)\n",
    "                plot_title = 'Metrics on Test Data'\n",
    "                metrics = ['micro_f1', 'micro_auprc', 'macro_auprc']\n",
    "                test1 = pd.read_csv(save_pred) if result is None else result\n",
    "\n",
    "            test = test1[test1['sensor_id'] != sid]\n",
    "            evenly_spaced_interval = np.linspace(0, 1, len(metrics))\n",
    "            colors = [cm.rainbow(x) for x in evenly_spaced_interval]\n",
    "            for i, metric in enumerate(metrics):\n",
    "                s = test1[test1['sensor_id'] == sid].iloc[0][metric]\n",
    "                sns.kdeplot(test[metric], color=colors[i], label=metric, ax=ax)\n",
    "                \n",
    "                xf, yf = ax.lines[i].get_data()\n",
    "                y = np.interp(s, xf, yf)\n",
    "                plt.vlines(s, ymin=0, ymax=y, color=colors[i], ls='--')\n",
    "            \n",
    "            ax.set_title(plot_title)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        pdf.savefig()\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:l3embedding-tf-2-gpu]",
   "language": "python",
   "name": "conda-env-l3embedding-tf-2-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
