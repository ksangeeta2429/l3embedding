{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import os\n",
    "import random\n",
    "import csv\n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import resampy\n",
    "import tensorflow as tf\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "from classifier.sonyc_ust.metrics import evaluate, micro_averaged_auprc, macro_averaged_auprc\n",
    "import oyaml as yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_from_tflite(cmsis_mels, tflite_model, input_index, output_index):\n",
    "    \n",
    "    predictions = []\n",
    "    #predictions per frame   \n",
    "    for idx in range(cmsis_mels.shape[0]):   #Ex of shape: (91, 64, 51)\n",
    "        x = np.array(cmsis_mels[idx])[np.newaxis, :, :, np.newaxis].astype(np.float32)\n",
    "        tflite_model.set_tensor(input_index, x)\n",
    "        tflite_model.invoke()\n",
    "        output = tflite_model.get_tensor(output_index)\n",
    "        predictions.append(output)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_output(output_path, test_file_list, y_pred, taxonomy):\n",
    "    \n",
    "    coarse_fine_labels = [[\"{}-{}_{}\".format(coarse_id, fine_id, fine_label)\n",
    "                           for fine_id, fine_label in fine_dict.items()]\n",
    "                          for coarse_id, fine_dict in taxonomy['fine'].items()]\n",
    "        \n",
    "    full_fine_target_labels = [fine_label for fine_list in coarse_fine_labels\n",
    "                               for fine_label in fine_list]\n",
    "        \n",
    "    coarse_target_labels = [\"_\".join([str(k), v])\n",
    "                            for k, v in taxonomy['coarse'].items()]\n",
    "        \n",
    "    with open(output_path, 'w') as f:\n",
    "        csvwriter = csv.writer(f)\n",
    "\n",
    "        # Write fields\n",
    "        fields = [\"audio_filename\"] + full_fine_target_labels + coarse_target_labels\n",
    "        csvwriter.writerow(fields)\n",
    "\n",
    "        # Write results for each file to CSV\n",
    "        for filename, y, in zip(test_file_list, y_pred):\n",
    "            filename = os.path.basename(filename.replace('npz', 'wav'))\n",
    "            row = [filename]\n",
    "\n",
    "            # Add placeholder values for fine level\n",
    "            row += [0.0 for _ in range(len(full_fine_target_labels))]\n",
    "            # Add coarse level labels\n",
    "            row += list(y)\n",
    "\n",
    "            csvwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cmsis_mels(file_list, taxonomy, output_path, model_path):\n",
    "    \n",
    "    y_pred_mean = []\n",
    "    interpreter = tf.lite.Interpreter(model_path=model_path) \n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    input_shape = input_details[0]['shape'][1:]\n",
    "    output_shape = output_details[0]['shape'][1:]\n",
    "    input_index = input_details[0]['index']\n",
    "    output_index = output_details[0]['index']\n",
    "\n",
    "    print(\"== Input details ==\")\n",
    "    print(interpreter.get_input_details()[0])\n",
    "    print(\"type:\", input_details[0]['dtype'])\n",
    "    print(\"\\n== Output details ==\")\n",
    "    print(interpreter.get_output_details()[0])\n",
    "\n",
    "    interpreter.allocate_tensors()\n",
    "    \n",
    "    for file in file_list:\n",
    "        cmsis_mels = np.load(file)['db_mels']\n",
    "        output = get_output_from_tflite(cmsis_mels, interpreter, input_index, output_index)\n",
    "\n",
    "        #coarse classes of sonyc = 8\n",
    "        pred_frame = np.array(output).reshape(-1, 8)\n",
    "        y_pred_mean.append(pred_frame.mean(axis=0).tolist())\n",
    "    \n",
    "    write_to_output(output_path, file_list, y_pred_mean, taxonomy)\n",
    "    assert os.path.exists(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pb_to_tflite(pb_model_dir=None, tflite_out_path=None):\n",
    "    # A list of the names of the model's input tensors\n",
    "    input_arrays = ['input_1']\n",
    "    # A list of the names of the model's output tensors\n",
    "    output_arrays = ['urban_sound_classifier/output/Sigmoid']\n",
    "\n",
    "    converter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(os.path.join(pb_model_dir, 'frozen_pipeline_cmsis_mels_quant.pb'),\n",
    "                                                                    input_arrays = input_arrays,\\\n",
    "                                                                    output_arrays = output_arrays)\n",
    "\n",
    "    #converter.inference_type = tf.int8\n",
    "    #converter.inference_input_type = tf.int8\n",
    "    input_arrays = converter.get_input_arrays()\n",
    "    #converter.default_ranges_min=0\n",
    "    #converter.default_ranges_max=6\n",
    "\n",
    "    flatbuffer = converter.convert()\n",
    "\n",
    "    with open(tflite_out_path, 'wb') as outfile:\n",
    "        outfile.write(flatbuffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_all(prediction_path, annotation_path, yaml_path, mode='coarse'):\n",
    "    \n",
    "    metrics = {\n",
    "        'coarse': {}\n",
    "    }\n",
    "\n",
    "    df_dict = evaluate(prediction_path,\n",
    "                       annotation_path,\n",
    "                       yaml_path,\n",
    "                       mode)\n",
    "\n",
    "    micro_auprc, eval_df = micro_averaged_auprc(df_dict, return_df=True)\n",
    "    macro_auprc, class_auprc = macro_averaged_auprc(df_dict, return_classwise=True)    \n",
    "\n",
    "     # Get index of first threshold that is at least 0.5\n",
    "    thresh_0pt5_idx = (eval_df['threshold'] >= 0.5).nonzero()[0][0]\n",
    "\n",
    "    metrics[mode][\"micro_auprc\"] = micro_auprc\n",
    "    metrics[mode][\"micro_f1\"] = eval_df[\"F\"][thresh_0pt5_idx]\n",
    "    metrics[mode][\"macro_auprc\"] = macro_auprc\n",
    "\n",
    "    print(\"{} level evaluation:\".format(mode.capitalize()))\n",
    "    print(\"======================\")\n",
    "    print(\" * Micro AUPRC:           {}\".format(metrics[mode][\"micro_auprc\"]))\n",
    "    print(\" * Micro F1-score (@0.5): {}\".format(metrics[mode][\"micro_f1\"]))\n",
    "    print(\" * Macro AUPRC:           {}\".format(metrics[mode][\"macro_auprc\"]))\n",
    "    print(\" * Coarse Tag AUPRC:\")\n",
    "\n",
    "    metrics[mode][\"class_auprc\"] = {}\n",
    "    for coarse_id, auprc in class_auprc.items():\n",
    "        coarse_name = taxonomy['coarse'][int(coarse_id)]\n",
    "        metrics[mode][\"class_auprc\"][coarse_name] = auprc\n",
    "        print(\"      - {}: {}\".format(coarse_name, auprc))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Input details ==\n",
      "{'name': 'input_1', 'index': 66, 'shape': array([ 1, 64, 51,  1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0)}\n",
      "type: <class 'numpy.float32'>\n",
      "\n",
      "== Output details ==\n",
      "{'name': 'urban_sound_classifier/output/Sigmoid', 'index': 85, 'shape': array([], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0)}\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    \n",
    "    model_dir = '/scratch/sk7898/quantization/pipeline_cmsis/'\n",
    "    model_ts = '20200224110114'\n",
    "    MODEL_DIR = os.path.join(model_dir, model_ts)\n",
    "    OUTPUT_DIR = os.path.join(MODEL_DIR, 'output/sonyc_ust/cmsis_val')\n",
    "    tflite_path = os.path.join(MODEL_DIR, 'qa_cmsis_model.tflite')\n",
    " \n",
    "    DATA_DIR = '/beegfs/dr2915/sonyc_ust'\n",
    "    annotation_path = os.path.join(DATA_DIR, 'annotations.csv')\n",
    "    yaml_path = os.path.join(DATA_DIR, 'dcase-ust-taxonomy.yaml')\n",
    "    test_data = glob.glob(os.path.join(DATA_DIR, 'db_mels/validate/*.npz'))[0:20]\n",
    "    prediction_path = os.path.join(OUTPUT_DIR, 'predictions.csv')\n",
    "    output_path = os.path.join(OUTPUT_DIR, 'output_mean.csv')\n",
    "    \n",
    "    if not os.path.isdir(OUTPUT_DIR):\n",
    "        os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "    with open(yaml_path) as f:\n",
    "        taxonomy = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "    if not os.path.exists(tflite_path):\n",
    "        convert_pb_to_tflite(pb_model_dir=MODEL_DIR, tflite_out_path=tflite_path)\n",
    "        \n",
    "    process_cmsis_mels(test_data, taxonomy, output_path, model_path=tflite_path)\n",
    "    #evaluate_all(output_path, annotation_path, yaml_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
